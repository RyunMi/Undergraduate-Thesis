# 为类不匹配的半监督学习回收可迁移的未标记数据

## 引用方式

### GB/T 7714

<span style="background-color: rgb(255, 255, 255)">Huang Z, Yang J, Gong C. They are not completely useless: Towards recycling transferable unlabeled data for class-mismatched semi-supervised learning[J]. IEEE Transactions on Multimedia, 2022.</span>

### Bibtex

    @article{huang2022they,
      title={They are not completely useless: Towards recycling transferable unlabeled data for class-mismatched semi-supervised learning},
      author={Huang, Zhuo and Yang, Jian and Gong, Chen},
      journal={IEEE Transactions on Multimedia},
      year={2022},
      publisher={IEEE}
    }

## 主要思想

具有不匹配类的半监督学习处理了有限标记数据中感兴趣的类只是大量未标记数据中类的子集的问题。

经典的SSL方法会被仅由未标记数据所拥有的类所误导，为了解决这个问题，最近的一些方法将未标记的数据分为有用的分布内数据和有害的分布外数据，其中后者尤其应该被削弱，即OOD数据所包含的潜在价值在很大程度上被忽视了。

为了弥补这一缺陷，本文提出了一种“可迁移OOD数据回收”方法，该方法正确地利用ID数据和“可回收”OOD数据来丰富进行类不匹配SSL的信息。具体而言，TOOR将与ID数据和标记数据有密切关系的OOD数据视为可回收数据，并采用对抗性域适应将其投影到ID数据和标签数据的空间中。换句话说，OOD数据的可回收性是通过其可转移性来评估的，可回收的OOD数据被转移，以便它们与已知兴趣类别的分布兼容。

TOOR比现有方法从未标记的数据中提取更多的信息，因此它实现了改进的性能，这在典型的基准数据集上的实验证明了这一点。

## 主要内容

### 引论

近期，SSL基于具有强大表示能力的深度神经网络取得了重大进展，其通常利用三种类型的训练策略来处理标记数据和未标记数据：

(1)熵最小化：促使网络对未标记的数据进行有信心的预测。

(2)一致性正则化：强制未标记数据上的扰动不应显著改变其标签预测。

(3)数据扩充：创建了额外的示例和标签信息，以提高学习到的分类器的泛化性。

上述SSL方法依赖于一个基本假设，即标记数据包含的类 $\mathcal{C}_l$ 和未标记数据包含的类 $\mathcal{C}_u$ 是相同的，即 $\mathcal{C}_l=\mathcal{C}_u$ 。在现实世界中，这样的假设很难满足，因为实际上事先不知道未标记数据的标签——类不匹配问题：标记数据 $\mathcal{C}_l$ 中的类构成未标记数据 $\mathcal{C}_u$ 中的类的子集，即 $\mathcal{C}_l\subset\mathcal{C}_u$ 。

属于类 $\mathcal{C}_l$ 的未标记数据被称为分布内(ID)数据，而未标记中仅属于 $\mathcal{C}_u$ 的数据被称为分布外(OOD)数据。由于OOD数据的存在，传统的SSL方法将被混淆，从而导致 $\mathcal{C}_l$ 中感兴趣的类的测试性能下降。

前人方法都认为OOD数据是有害的，因此未能充分利用其潜在价值。本文认为检测到的OOD数据并不是完全无用的，其中的一些内容丰富，实际上可以以适当的方式（“回收”）重复使用，以提高分类性能。

![\<img alt="" data-attachment-key="BZ5TSJ53" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22H7N6I7BD%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B310.05372413277297%2C384.375%2C568.085%2C595.507%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%221%22%7D%7D" width="430" height="352" src="attachments/BZ5TSJ53.png" ztype="zimage">](attachments/BZ5TSJ53.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 1</a></span>)</span>

本文(TOOR)在每一轮训练中将整个未标记集划分为三个子集，即ID数据、可回收OOD数据和不可回收OOD数据，其中只有最后一个子集在训练网络时被丢弃。

这里根据ID数据的softmax得分会高于OOD数据的softmax得分来自动检测ID数据，而可回收OOD数据和不可回收OOD数据则通过评估它们到标记图像特征空间的可迁移性来决定。

对于可回收的OOD数据，由于其分布与标注数据仍有细微差异，本文提出通过对抗学习进行域适应，以减小两个特征分布之间的潜在差距。

由于可迁移OOD数据的重复使用，本文的TOOR方法可以由许多现有的SSL方法(Mean Teacher, Virtual Adversarial Training)整合。

### TOOR方法

$\mathcal{X}$ :特征空间； $\mathcal{Y}$ :标签空间；给定一组训练图像示例 $\mathcal{D}=\{\mathrm{x}\_i \in \mathcal{X} \subset \mathbb{R}^d, i=1,2, \cdots, n, n=l+u. \text{with} .l \ll u\}$ ，其中前 $l$ 个图像示例被标记为 $\{y_i\}^l_{i=1}\in \mathcal{Y}=\{1,2,\cdots,c\}$ ，其中 $c$ 是已知类的数量，并且剩余的 $u$ 个图像示例是未标记的。

使用 $\mathcal{D}\_l=\{(x_1,y_1),(x_2,y_2),\cdots,(x_l,y_l)\}$ 来表示从 $\mathcal{X}\times \mathcal{Y}$ 上定义的联合分布 $P_{\mathcal{X}\times \mathcal{Y}}$ 中提取的有标签集合。并且 $\mathcal{D}\_u=\{x_{l+1},x_{l+2},\cdots,x_{l+u}\}$ 来表示从边际分布 $P_{\mathcal{X}}$ 采样的未标记集合。标记数据和未标记数据的边际分布 $P_{\mathcal{X}}$ 是相同的。

然而，假设 $\mathcal{D}\_u$ 由标签在 $\mathcal{Y}$ 中的ID数据集 $\mathcal{D}\_{id}$ 和标签在 $\mathcal{Y}'$ 中的OOD数据集 $\mathcal{D}\_{ood}$ 组成，通常 $\mathcal{Y}\in\mathcal{Y}'$ ，即 $\mathcal{D}\_u=\mathcal{D}\_{id}\cup\mathcal{D}\_{ood}$ 。

因此，在标记数据 $P_{\mathcal{X}\times \mathcal{Y}}$ 和未标记数据 $P_{\mathcal{X}\times \mathcal{Y}'}$ 的真实联合分布之间存在分布差距。

TOOR的主要目标是有效地利用类不匹配的训练集 $\mathcal{D}=\mathcal{D}_l\cup\mathcal{D}_u$ 来找到一个半监督分类器，该分类器可以适当地利用 $\mathcal{D}_u$ ，从而可以正确地对任何具有未知标签 $y\in\mathcal{Y}$ 的看不见的图像 $x$ 进行分类。TOOR的模型可以简明地公式化为：

![\<img alt="" data-attachment-key="NYNE5EYX" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%227GNF5AU7%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B57.99100000000001%2C38.68299999999992%2C279.82%2C181.8016628065345%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%223%22%7D%7D" width="370" height="239" src="attachments/NYNE5EYX.png" ztype="zimage">](attachments/NYNE5EYX.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 3</a></span>)</span>

其中 $F$ 是图像特征提取器， $C$ 是分类器， $D$ 是判别器， $\theta_F,\theta_C,\theta_D$ 分别是它们的参数。符号 $|\cdot|$ 表示相应集合的大小。

第一项称为监督保真度项，它涉及标准的交叉熵损失 $\mathcal{L}_{ce}(\cdot)$ ，用于比较每个标记图像上的网络预测 $C(F(x_i))$ 及其真实标记 $y_i$ 。

第二项是指ID数据探索项，其中 $\mathcal{L}_{ssl}(\cdot)$ 表示在ID数据上定义的损失，它可以是现有SSL方法中的任何正则化项，如一致性正则化项或流形正则化项。

第三个项被称为OOD数据回收项，它引入了对抗性学习损失 $\mathcal{L}_{adv}(\cdot)$ 来“回收”可迁移的OOD数据。

这里，OOD数据是通过检查其可迁移性得分 $w(x_i)$ 来发现的，通过这样的回收过程，TOOR方法可以最大限度地利用类不匹配的数据集，而不包括无用或有害的OOD数据，同时重用可迁移的未标记图像示例所包含的丰富信息，从而获得优于其他方法的性能。

![\<img alt="" data-attachment-key="2KNI87ID" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%222FJ3AYHA%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B97.402%2C600.574%2C512.1769992017703%2C749.9988926077722%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%223%22%7D%7D" width="691" height="249" src="attachments/2KNI87ID.png" ztype="zimage">](attachments/2KNI87ID.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 3</a></span>)</span>

给定标记图像集 $\mathcal{D}_l$ 和未标记图像集 $\mathcal{D}_u$ ，使用特征提取器 $F$ 来计算 $x\in\mathcal{D}_l\cup\mathcal{D}_u$ 的特征表示 $F(x)$ 。

然后对 $F(x)$ 施加分类器 $C$ ，以获得每个输入图像的标签预测向量 $f(x)$ 。

基于 $f(x)$ ，可以找到与标记的数据一起用于计算 $\mathcal{L}_{ssl}$ 的 ID 数据。

而所确定的OOD数据被进一步发送到对抗学习分支，使得可回收的OOD数据被收回，不可回收的OOD数据被完全丢弃。具体地说，所有用可迁移性得分加权的OOD数据都与ID数据相结合，以充当生成器，并且它们被用来混淆判别器D，D应尽力将所呈现的数据区分为ID数据(1)或OOD数据(0)。

在OOD数据检测和用于回收的对抗学习之间的迭代过程中，检测到的ID数据集通过逐渐吸收所考虑的ID图像和可迁移的OOD图像，从初始的有限标记图像集扩展而来。

#### OOD数据检测

可通过研究网络训练期间未标记数据的softmax分数来实现。具体而言，给定输入图像 $x$ ，分类器输出的其标签预测 $f(x)$ 是 $c$ 维向量 $[f_1(x),f_2(x),\cdots,f_c(x)]^\top$ ，其中 $\{f_i(x)\}^c_{i=1}$ 可被解释为 $x$ 属于类 $i$ 的概率。本文实现缩放标签预测 $S(x;\tau)=[S_1(x;\tau),S_2(x;\tau),\cdots,S_c(x;\tau)]^\top$ ，其中( $\tau\in\mathbb{R}^+$ 是一个温度缩放参数，控制分布的集中程度)：

![\<img alt="" data-attachment-key="TU7RZCMB" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22ADI82UF3%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B104.72099999999999%2C460.3829999999999%2C240.40799999999996%2C488.42096828822156%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%224%22%7D%7D" width="226" height="47" src="attachments/TU7RZCMB.png" ztype="zimage">](attachments/TU7RZCMB.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 4</a></span>)</span>

$S(x;\tau)$ 中元素的最大值被称为softmax分数。ID数据的softmax分数显著大于OOD数据的softmax分数，因此可以利用不同示例的softmax得分来将未标记的图像判断为ID数据或OOD数据。

由于上述ID数据集在训练过程中的逐渐扩展，某些OOD数据的softmax分数可能会振荡，这使得它们的OOD数据检测结果在连续迭代中不一致。为了解决这个问题，本文在计算softmax分数之前进行**时间聚合**，以实现对所有未标记数据的稳定预测。

具体来说，使用EMA来组装历史迭代中未标记数据的标签预测，EMA为最近的预测分配更大的权重，同时指数级地降低早期预测的权重。因此， $x$ 的组合标签预测计算为：

![\<img alt="" data-attachment-key="EL6I44XN" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%226GD47C7I%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B73.192%2C128.202%2C269.122%2C150.16%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%224%22%7D%7D" width="327" height="37" src="attachments/EL6I44XN.png" ztype="zimage">](attachments/EL6I44XN.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 4</a></span>)</span>

其中 $S(x;\tau)^{(t)}$ 表示缩放标签预测，其元素在第 $t$ 次迭代时计算。 $\hat{S}(x;\tau)^{(t)}$ 和 $\hat{S}(x;\tau)^{(t-1)}$ 分别表示第 $t$ 次迭代和 $t-1$ 次迭代时的组合标签预测。系数 $\eta\in[0,1]$ 是一个动量参数，决定了聚合与训练历史的距离。 $\hat{S}(x;\tau)$ 中元素的最大值被称为稳定softmax分数。

给定稳定softmax分数 $\hat{s}(x)$ ，使用一个OOD阈值 $\delta$ 来分离未标记集合 $\mathcal{D}_u$ 中的OOD数据和ID数据。具体来说，如果一幅图像的稳定softmax得分大于 $\delta$ ，则认为该图像为ID数据，否则为OOD数据。

通过引入 $t(x;\delta)$ 作为关于 $x$ 的指示变量：

![\<img alt="" data-attachment-key="ZV8JUB2A" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22TWT5F4JB%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B379.474%2C531.323%2C492.077%2C565.667%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%224%22%7D%7D" width="188" height="57" src="attachments/ZV8JUB2A.png" ztype="zimage">](attachments/ZV8JUB2A.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 4</a></span>)</span>

被确定为ID数据后将被 $\mathcal{D}_{id}$ 合并以计算公式中的ID数据探索项。

#### 面向回收的对抗学习

希望在 $\mathcal{D}\_{ood}$ 中找到可回收的图像，然后将它们转移到 $\mathcal{D}\_{l}\cup\mathcal{D}\_{id}$ 的空间中，这样它们所包含的信息就可以被充分地提取出来用于训练半监督分类器。

为此，将 $\mathcal{D}\_{ood}$ 作为源分布， $\mathcal{D}\_{l}\cup\mathcal{D}\_{id}$ 作为目标分布，并提出利用对抗域适应技术来缓解分布差异。将 $\mathcal{D}\_{l}\cup\mathcal{D}\_{id}$ 作为目标分布是因为 $\mathcal{D}\_l$ 包含的标记数据非常有限，不能忠实地反映相应的分布，并且可能导致得到的分类器的泛化性较差。

具体来说，通过最小化交叉熵损失来学习判别器 $D$ 的参数 $\theta_D$ 来区分之前识别的OOD数据和ID数据。同时，学习到的特征提取器 $F$ 的参数 $\theta_F$ ，通过最大化相同的交叉熵损失来欺骗判别器。这样，ID数据和可迁移的OOD数据之间的域迁移是封闭的，其中"容易"迁移的OOD数据很可能被回收。

对可回收的OOD数据进行对抗训练，促使模型对一些不确定的ID数据产生有信心的预测从而提高模型稳健性。

![\<img alt="" data-attachment-key="KG9G2K54" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22ULZCHD3U%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B54.05%2C635.481%2C289.391%2C698.539%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%225%22%7D%7D" width="392" height="105" src="attachments/KG9G2K54.png" ztype="zimage">](attachments/KG9G2K54.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 5</a></span>)</span>

其中 $w(x_i)$ 是有助于发现可回收OOD数据的可迁移性评分。

还通过最小化原始标记数据上的监督交叉熵损失 $\mathcal{L}_{ce}$ 来训练分类器 $C$ ，这与对抗学习同时进行。因此可以成功地从OOD数据中提取有用的知识，用于在感兴趣的标签空间 $Y$ 上的分类任务。

首先，如果判别器 $D$ 无法判断图像 $x_i\in D_u$ 是来自源域还是目标域，即 $x_i$ 是非常模糊的，因为它的表示接近于ID数据和OOD数据。因此它很可能是一个可迁移的图像示例，应该被回收。为此引入了一个**领域相似度分数** $w_d(x_i)$ 。

其次，若分类器 $C$ 很倾向于将 $x_i$ 归属于某个类 $y\in Y$ ，即 $x_i$ 可能属于这个类，因此应该回收。为此引入了一个**类别倾向分数** $w_c(x_i)$ 。

通过自适应地集成 $w_d(x_i)$ 和 $w_c(x_i)$ ，可获得任意 $x_i\in D_u$ 的可迁移性分数 $w(x_i)$ 。

##### **领域相似度分数**

训练判别器 $D$ 来区分ID数据和OOD数据，其输出可以解释为：

![\<img alt="" data-attachment-key="IWYK75W2" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%2286HZJKYB%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B89.52%2C198.017%2C255.61%2C214.907%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%225%22%7D%7D" width="277" height="28" src="attachments/IWYK75W2.png" ztype="zimage">](attachments/IWYK75W2.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 5</a></span>)</span>

因此如果 $D(F(x_i))$ 很大，则 $x_i$ 与已知空间 $\mathcal{D}\_{l}\cup\mathcal{D}\_{id}$ 相似，应该通过赋予这些示例较大的分数来适当地回收这些它们。因此，反映领域信息的分数表示为： $\tilde{w}\_d(x_i)=D(F(x_i))$ 。

为了获得跨OOD数据的更有判别力的评分分配，将所有未标记数据的评分归一化以计算领域相似度评分：

![\<img alt="" data-attachment-key="FACPEKYU" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%227NKZZ95I%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B358.079%2C663.632%2C512.346%2C696.85%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%225%22%7D%7D" width="257" height="55" src="attachments/FACPEKYU.png" ztype="zimage">](attachments/FACPEKYU.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 5</a></span>)</span>

其有助于扩大潜在可回收OOD数据的得分，同时降低不可迁移OOD数据的得分，防止其被回收。

##### **类别倾向分数**

由于分类器 $C$ 是在有标签集合 $\mathcal{D}_l$ 上训练的，具有较高的判别性，因此ID数据的组合标签预测可以为评估可迁移性提供有价值的线索。本文利用组合标签预测向量 $\hat{S}(x;\tau)$ 的最大和次大元素之间的预测间隔来建立类别倾向得分，其计算公式为：

![\<img alt="" data-attachment-key="RR59H5WR" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22R83AUDTI%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B313.038%2C443.492%2C541.06%2C466.576%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%225%22%7D%7D" width="380" height="38" src="attachments/RR59H5WR.png" ztype="zimage">](attachments/RR59H5WR.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 5</a></span>)</span>

如果一个OOD实例的预测间隔很大，说明该实例对某个类别有较大的倾向性，那么将这类OOD实例视为可迁移数据，并将其回收到相应的类别 $j$ 中。也将 $\tilde{w}_c(x_i)$ 归一化：

![\<img alt="" data-attachment-key="RGM2V945" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22DPDDS6DN%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B359.107%2C203.122%2C513.733%2C233.469%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%225%22%7D%7D" width="258" height="51" src="attachments/RGM2V945.png" ztype="zimage">](attachments/RGM2V945.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 5</a></span>)</span>

##### 自适应集成

通过使用向量 $w_d=[w_d(x_1),\cdots,w_d(x_{|\mathcal{D}\_{ood}|})]^\top$ 和 $w_c=[w_c(x_1),\cdots,w_c(x_{|\mathcal{D}\_{ood}|})]^\top$ 来编码所有 $x_i\in\mathcal{D}\_{ood}$ 的领域相似度得分和类别倾向得分，本文提出利用它们的方差来计算权衡权重。具体来说，如果 $w_d(x_i)$ 或 $w_c(x_i)$ 的方差较大，意味着所包含元素的值对于表征所有 $x_i\in\mathcal{D}\_{ood}$ 的可迁移性具有判别性，那么在构成最终的可迁移性得分 $w(x_i)$ 时需要重点关注。数学上，有如下凸组合：

![\<img alt="" data-attachment-key="ZP66A8S6" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22UA89ZWJV%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B95.713%2C465.45%2C249.417%2C520.626%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%226%22%7D%7D" width="256" height="92" src="attachments/ZP66A8S6.png" ztype="zimage">](attachments/ZP66A8S6.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 6</a></span>)</span>

可迁移的OOD数据经过上述加权的极大-极小博弈回收后，其特征表示将落入 $\mathcal{D}\_{l}\cup\mathcal{D}\_{id}$ 的特征空间，从而充当ID数据。此外，它们将被纳入SSL训练，以提高分类任务在感兴趣类上的性能。

#### 半监督训练

可利用有用的原始标记数据、ID数据和可回收的OOD数据，通过将任何现有的SSL正则化项部署到 $\mathcal{L}\_{ssl}$ 来实现半监督训练。如一致性损失、虚拟对抗训练损失，熵最小化等。因此以通过在ID数据探索项中指定SSL正则化项 $\mathcal{L}\_{ssl}$ 替换，同时用加权极大-极小博弈替换OOD数据回收项，来实例化TOOR算法的一般框架。

![\<img alt="" data-attachment-key="52B7LUFL" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22UR3P5EP8%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B47.293%2C597.759%2C301.214%2C743.017%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%226%22%7D%7D" width="423" height="242" src="attachments/52B7LUFL.png" ztype="zimage">](attachments/52B7LUFL.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 6</a></span>)</span>

## 结论及改进方向

### 实验

#### 实现细节

TOOR使用100大小的批量，并且经过500000次迭代的训练。网络训练由Adam优化器进行，在400000次迭代后，权重衰减因子为0.2。所有的实验都可以在单个P40 GPU上进行，并且需要8个小时来训练。

##### 主干网络

选择Wide ResNet-28-2作为骨干网络 $F$ 。

![\<img alt="" data-attachment-key="WXSHX3QG" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22UNGWFMX5%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B310.786%2C281.906%2C561.328%2C570.171%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%226%22%7D%7D" width="418" height="481" src="attachments/WXSHX3QG.png" ztype="zimage">](attachments/WXSHX3QG.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 6</a></span>)</span>

注意，“Horizontal flip”不应用于SVHN，因为这样的数据集很简单，“Horizontal flip”不会带来进一步的性能改进。

##### 判别器

![\<img alt="" data-attachment-key="XB9H5K9R" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22H5J8C842%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B382.852%2C153.538%2C489.825%2C254.318%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%226%22%7D%7D" width="178" height="168" src="attachments/XB9H5K9R.png" ztype="zimage">](attachments/XB9H5K9R.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 6</a></span>)</span>

GRL中的翻转系数 $flip\_coeff$ 旨在训练过程的早期阶段抑制来自判别器的噪声信号，其从0到1递增，符合函数：

![\<img alt="" data-attachment-key="5PK297WP" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22S3HABQF4%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B47.29300000000001%2C284.04562330202094%2C226.333%2C300.5983509390092%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%227%22%7D%7D" width="298" height="28" src="attachments/5PK297WP.png" ztype="zimage">](attachments/5PK297WP.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 7</a></span>)</span>

其中 $iter$ 表示当前训练迭代， $pretrain\_iter$ 表示监督训练的迭代次数，在实验中设置为5000。

一些域适应方法使用额外的非对抗判别器来产生可迁移性。然而在类不匹配问题中，使用一个非对抗的判别器并不能带来进一步的性能提升。

#### 单一数据集场景评估

在每个单一数据集中创建有标签和无标签数据之间的类不匹配情况。

CIFAR10包含50000张和10000张大小为32×32的自然图像用于训练和测试，分别由6个动物类(如'鸟'、'猫'、'鹿'、'狗'、'青蛙'、'马'等)和4个交通工具类(例如"飞机"、"汽车"、"轮船"、"卡车"等)组成。这里从训练集中的6个动物类别中各随机选择400张图像来构建标记集，从所有10个类别中挑选20000张训练图像组成未标记集。这样，属于动物类的图像为ID数据，属于交通工具类的图像为OOD数据。

SVHN由73257张训练图像和26032张测试图像组成，分辨率为32×32，采集自真实房屋编号。该数据集包含十类，即十位数字0到9。从训练集中的6个类0到5中各随机选取100张图像组成标记集，从所有10个类0到9中随机抽取20000张训练图像组成未标记集。

##### 与传统SSL方法比较

对于TOOR，采用 $\Pi-$ 模型中使用的一致性正则化作为SSL正则化器 $\mathcal{L}_{ssl}$ 。

![\<img alt="" data-attachment-key="KAC56WMG" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%229AGZE2UX%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B95.713%2C577.49%2C516.85%2C739.639%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%227%22%7D%7D" width="702" height="270" src="attachments/KAC56WMG.png" ztype="zimage">](attachments/KAC56WMG.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 7</a></span>)</span>

##### 与类不匹配SSL方法比较

![\<img alt="" data-attachment-key="X33GTMGA" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22CKQWP8PH%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B93.461%2C576.927%2C516.85%2C741.328%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%228%22%7D%7D" width="706" height="274" src="attachments/X33GTMGA.png" ztype="zimage">](attachments/X33GTMGA.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 8</a></span>)</span>

TOOR相当通用，可以帮助许多传统SSL方法解决类不匹配问题。

#### 跨数据集场景评估

包含的有标签和无标签数据之间的分布差距比单数据集场景大得多。

选择CIFAR100和ImageNet分别构成有标签和无标签集合。CIFAR100具有与CIFAR10相同的图像数据，但包含100类。ImageNet包含来自1000个类别的1331167张图像。

为了创建用于评估的数据集，从CIFAR100中的60个类中选择了6000张图像作为标记集。然后从ImageNet中的100个类中抽取20000张图像组成未标记集，该未标记集包含了标记集中所选类所对应的60个类。此外，未标记集合中剩余的40个类是从ImageNet中剩余的940个类中随机选取的。

![\<img alt="" data-attachment-key="YFLFTIJ4" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22RQYB8U6K%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B340.063%2C377.619%2C534.867%2C513.306%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%228%22%7D%7D" width="325" height="226" src="attachments/YFLFTIJ4.png" ztype="zimage">](attachments/YFLFTIJ4.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 8</a></span>)</span>

在构建的数据集上，TOOR明显优于所有其他对比方法，这表明了TOOR在处理大类不匹配情况下的挑战性分类任务的能力。

#### 对不同数量的实例进行实验

验证方法在有标签和无标签样本数量变化下的鲁棒性。

将未标记数据点的数量固定为20000，只改变已标记样本的数量。

![\<img alt="" data-attachment-key="25A8IKXG" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22WWHD2CWJ%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B81.638%2C544.835%2C528.11%2C717.119%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%229%22%7D%7D" width="744" height="287" src="attachments/25A8IKXG.png" ztype="zimage">](attachments/25A8IKXG.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 9</a></span>)</span>

固定每个数据集中有标签样本的数量，只改变无标签样本的数量。

![\<img alt="" data-attachment-key="32JU95IU" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22BUPXCD2X%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B77.133%2C339.897%2C530.925%2C512.743%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%229%22%7D%7D" width="756" height="288" src="attachments/32JU95IU.png" ztype="zimage">](attachments/32JU95IU.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 9</a></span>)</span>

#### 性能研究

首先为了证明OOD阈值 $\delta$ 的不同值的影响，在SVHN，CIFAR10和CIFAR100+ImageNet等不同数据集上对OOD阈值 $\delta$ 进行了参数敏感性分析。

![\<img alt="" data-attachment-key="3R43MIPB" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22AGZJMRZ4%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2210%22%2C%22position%22%3A%7B%22pageIndex%22%3A9%2C%22rects%22%3A%5B%5B46.73%2C527.945%2C295.021%2C738.513%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2210%22%7D%7D" width="414" height="351" src="attachments/3R43MIPB.png" ztype="zimage">](attachments/3R43MIPB.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2210%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 10</a></span>)</span>

可以发现，当 $\delta$ 从0.8增加到0.9时，所有三个数据集的学习精度都会提高，这是因为有害的OOD数据被正确地过滤掉了。然而当 $\delta$ 从0.9增加到0.99时，学习性能会下降，这是因为大多数ID数据以及可迁移的OOD数据都被错误地排除在训练之外。

为了显示稳定softmax分数的合理性，下图展示了SVHN、CIFAR10和CIFAR100+ImageNet数据集的ID数据和OOD数据的分数。

![\<img alt="" data-attachment-key="QFSEU4HG" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%229MQCIECH%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2210%22%2C%22position%22%3A%7B%22pageIndex%22%3A9%2C%22rects%22%3A%5B%5B306.845%2C552.155%2C563.58%2C737.95%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2210%22%7D%7D" width="428" height="310" src="attachments/QFSEU4HG.png" ztype="zimage">](attachments/QFSEU4HG.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2210%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 10</a></span>)</span>

在SVHN和CIFAR10数据集中，大多数ID数据的得分接近1，而OOD数据的得分大致显示出均匀分布，因为它们中的大多数被排除在网络训练之外。即计算的softmax得分在区分ID数据和OOD数据方面提供了有价值的信息。

CIFAR100+ImageNet数据集中，大多数ID数据的得分仍然大于OOD数据的得分，因此计算的softmax得分仍然是一个令人满意的标准。

为了证明OOD数据检测可以识别可回收OOD数据，同时避免过度检测不可循环OOD数据，如下表所示。

![\<img alt="" data-attachment-key="NHE2XPCF" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22QFJ8HTLS%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2210%22%2C%22position%22%3A%7B%22pageIndex%22%3A9%2C%22rects%22%3A%5B%5B309.66%2C414.215%2C564.144%2C466.013%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2210%22%7D%7D" width="424" height="86" src="attachments/NHE2XPCF.png" ztype="zimage">](attachments/NHE2XPCF.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2210%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 10</a></span>)</span>

可回收OOD数据的不稳定softmax得分接近ID数据的得分，并且与可回收OOD数据相比，不可回收OOD数据的softmax得分保持相对较低，这表明我们的OOD数据检测可以正确识别ID数据和可回收OOD数据，同时避免过度检测过多有害的不可回收OOD数据。

![\<img alt="" data-attachment-key="M9KVP977" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%225XX4FABN%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B100.78%2C342.712%2C246.602%2C395.636%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2211%22%7D%7D" width="243" height="88" src="attachments/M9KVP977.png" ztype="zimage">](attachments/M9KVP977.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 11</a></span>)</span>

有相对较小比例的OOD数据被回收并纳入网络训练，大多数OOD数据仍然被视为应该被忽略的有害部分，这意味着回收过程是有选择性的，不会受到太多有害OOD数据的影响。

使用t-SNE方法对Wide ResNet-28-2提取的SVHN和CIFAR10数据集的图像特征进行了可视化。

![\<img alt="" data-attachment-key="UYBL5DLP" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22NWLKH6FW%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B46.73%2C525.693%2C577.4870268006662%2C755.9670000000001%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2211%22%7D%7D" width="885" height="384" src="attachments/UYBL5DLP.png" ztype="zimage">](attachments/UYBL5DLP.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 11</a></span>)</span>

对于SVHN数据集，可以观察到，大多数可迁移性得分相对较大的回收OOD数据（绿点）位于每个聚类内的密集区域，而可迁移性分数较小的OOD数据则以分散的方式分布。此外，回收的OOD图像数据与标记集中的类显示出很大的相似性。例如，我们可以看到，许多对应于数字“9”的OOD数据被映射到类为“0”的ID数据，因为这两个数字看起来很相似。相比之下，红框中的大多数不可回收OOD数据都是模糊的，其中一些甚至无法被人类识别。因此，通过给这些不可回收的OOD数据分配较小的可转移性分数，设法减轻了它们的负面影响。CIFAR10类似。

#### 消融研究

OOD数据检测利用EMA平滑来通过温度缩放以稳定softmax分数。在这里将OOD数据检测的稳定softmax分数分解为四个实验设置，即“w/o EMA和温度”、“有温度”、”有EMA“和”TOOR“。

![\<img alt="" data-attachment-key="CU2CU5JS" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22ZNVA5VKX%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2212%22%2C%22position%22%3A%7B%22pageIndex%22%3A11%2C%22rects%22%3A%5B%5B91.772%2C656.876%2C514.035%2C713.178%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2212%22%7D%7D" width="704" height="94" src="attachments/CU2CU5JS.png" ztype="zimage">](attachments/CU2CU5JS.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2212%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 12</a></span>)</span>

对所提出的领域相似性得分和类倾向性得分进行了消融研究，以分析OOD数据回收过程中的可转移性评估。将TOOR的可转移性分解为四个实验设置，即“w/o两个分数”、“具有领域相似性分数”、”具有类倾向性分数“和”TOOR“。此外添加一个比较基准设置“w/o recycle”，表示没有回收的训练。

![\<img alt="" data-attachment-key="G8JGG2S9" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FD9WQ5P9J%22%2C%22annotationKey%22%3A%22YNIX74ZB%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2212%22%2C%22position%22%3A%7B%22pageIndex%22%3A11%2C%22rects%22%3A%5B%5B46.167%2C573.549%2C568.648%2C627.036%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2212%22%7D%7D" width="871" height="89" src="attachments/G8JGG2S9.png" ztype="zimage">](attachments/G8JGG2S9.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FEVE3BWCB%22%5D%2C%22locator%22%3A%2212%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/EVE3BWCB">Huang 等, 2022, p. 12</a></span>)</span>

### 未来工作

未来，计划研究一个更复杂的情况，即在标记数据中存在一些私有类。在这种情况下，标记数据所拥有的私有类可能会误导对未标记数据的学习。此外，与具有大量未标记数据的其他类相比，私有类仅包含稀缺的标记数据，从而导致类不平衡问题。因此，应该制定更先进的可回收数据识别策略来解决这一问题。
