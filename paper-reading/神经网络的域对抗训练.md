# 神经网络的域对抗训练

## 引用方式

### GB/T 7714

<span style="background-color: rgb(255, 255, 255)">Ganin Y, Ustinova E, Ajakan H, et al. Domain-adversarial training of neural networks[J]. The journal of machine learning research, 2016, 17(1): 2096-2030.</span>

### BibTex

    @article{ganin2016domain,
      title={Domain-adversarial training of neural networks},
      author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
      journal={The journal of machine learning research},
      volume={17},
      number={1},
      pages={2096--2030},
      year={2016},
      publisher={JMLR. org}
    }

## 概念名词

**VC维：**对于一个分类模型，VC等于一个最大的数据集大小，不管如何给定标号，都存在一个模型对它进行完美分类。

## 主要思想

本文引入了一种新的域适应表示学习方法，其中训练和测试时的数据来自相似但不同的分布。受域适应理论的启发(为了实现有效的域迁移，必须基于不能区分源域和目标域的特征进行预测)，方法在基于来自源域的标记数据和来自目标域的未标记数据训练的神经网络架构的条件下实现。

随着训练的进行，方法促进了以下特征的出现：(i)对源域上的主要学习任务具有判别性；(ii)对域之间的偏移不加区分。通过用很少的标准层和新的梯度反转层来增强前馈模型，这种适应操作几乎可以在任何前馈模型中实现，所得到的增强架构可以使用标准反向传播和随机梯度下降来训练。

本文证明了方法对于两个不同的分类问题(文档情感分析和图像分类)的成功，其中在benchmark上实现了最先进的域适应性能。本文还验证了在行人重识别应用的环境中描述学习任务的方法。

## 主要内容

### 引言

对于缺少标记数据的问题，可能仍然可以获得足够大的训练集来训练大规模深度模型，但这些训练集会受到数据分布与“测试时”遇到的实际数据的变化的影响。

域适应方法在源域（训练）和目标域（测试）之间建立映射，从而当与域之间学习到的映射组合时，为源域学习的分类器也可以应用于目标域。域适应方法的吸引力在于，当目标域数据完全未标记（无监督）或具有少量标记样本（半监督）时，能够学习域之间的映射。

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B150.712%2C228.708%2C228.819%2C238.395%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%222%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/J6JJQIM8?page=2">“Ben-David et al”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 2</a></span>)</span>的理论表明：跨域迁移的良好表示是算法无法识别输入观测值来源的域。

### 域适应

$X$ ：输入空间； $Y=\{0,1,\dots,L-1\}$ ：L个可能标签的集合； $\mathcal{D}_S,\mathcal{D}_T$ ：源域和目标域

![\<img alt="" data-attachment-key="M5AZVCIA" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22UD7CEP6H%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B172.846%2C304.99%2C433.523%2C324.132%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%225%22%7D%7D" width="434" height="32" src="attachments/M5AZVCIA.png" ztype="zimage">](attachments/M5AZVCIA.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 5</a></span>)</span>

$N=n+n'$ ：样本总量；学习算法的目标是在没有关于 $\mathcal{D}_T$ 的标签信息基础上建立一个使目标风险低的分类器 $\eta:X\rightarrow Y$ ：

![\<img alt="" data-attachment-key="3GXZ3TPW" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22VPICAEIZ%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B228.022%2C237.428%2C377.785%2C262.764%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%225%22%7D%7D" width="250" height="42" src="attachments/3GXZ3TPW.png" ztype="zimage">](attachments/3GXZ3TPW.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 5</a></span>)</span>

#### 域散度

为了解决域适应任务，许多方法通过源域误差、源域与目标域分布之间的距离概念 之和限制目标误差。简单的假设：当两种分布相似时，源域风险预计是目标域风险的良好指标。

本文以 $\mathcal{H}$ 散度为重点，并且假设：函数类 $\mathcal{H}$ 是一组（离散或连续）二元分类器 $\eta:X\rightarrow\{0,1\}$ \[多类设置也有同样的分析。然而，为了在 $|Y|>2$ 时获得相同的结果，应该假设 $\mathcal{H}$ 是一个对称的假设类——对于所有 $h\in\mathcal{H}$ 和标签的任何置换映射 $c:Y\rightarrow Y$ ，有 $c(h)\in\mathcal{H}$ 。这是最常用的神经网络架构情况]。

**定义1：**给定 $X$ 上的两个域分布 $D^X_S$ 和 $D^X_T$ 以及函数类 $\mathcal{H}$ ， $D^X_S$ 和 $D^X_T$ 之间的 $\mathcal{H}$ 散度为：

![\<img alt="" data-attachment-key="7K9ZRF74" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22NMP9G93F%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B145.259%2C586.499%2C455.481%2C618.028%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%226%22%7D%7D" width="517" height="53" src="attachments/7K9ZRF74.png" ztype="zimage">](attachments/7K9ZRF74.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 6</a></span>)</span>

<span style="background-color: rgb(255, 255, 255)">定义1的含义是用某一个领域的数据训练出来的分类器，在两个领域上预测结果，其预测损失就作为这两个领域差异的上界。</span> $\mathcal{H}$ <span style="background-color: rgb(255, 255, 255)">散度依赖于假设类</span> $\mathcal{H}$ <span style="background-color: rgb(255, 255, 255)">区分</span> $D^X_S$ <span style="background-color: rgb(255, 255, 255)">生成的示例和</span> $D^X_T$ <span style="background-color: rgb(255, 255, 255)">生成的示例的能力。</span>

对于对称假设类 $\mathcal{H}$ ，可以通过计算 $S\sim (D^X_S)^n$ 和 $T\sim (D^X_T)^{n'}$之间的**经验 $\mathcal{H}$ 散度**来近似：

![\<img alt="" data-attachment-key="J5SDENHU" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%223GVT8TW4%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B136.25%2C482.4529967531768%2C470.11999999999995%2C521.3012028249341%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%226%22%7D%7D" width="556" height="65" src="attachments/J5SDENHU.png" ztype="zimage">](attachments/J5SDENHU.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 6</a></span>)</span>

#### 代理距离

即使难以精确计算 $\hat{d}_{\mathcal{H}}$ (当 $\mathcal{H}$ 是 $X$ 上线性分类器的空间)，也可以通过运行学习算法区分源域与目标域样本。为此，构建一个新的数据集：

![\<img alt="" data-attachment-key="2KKWAPH8" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%226JNJ87IZ%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B216.19899999999998%2C350.03100000000006%2C385.667%2C371.20073940694726%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%226%22%7D%7D" width="282" height="35" src="attachments/2KKWAPH8.png" ztype="zimage">](attachments/2KKWAPH8.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 6</a></span>)</span>

**其中源域样本的实例被标记为0，而目标域样本的实例标记为1。**

在区分源域和目标域示例的问题上给定泛化误差 $\epsilon$ ，则 $\mathcal{H}$ 散度近似为 $\hat{d}_{\mathcal{A}}=2(1-2\epsilon)$ ，此即**代理 $\mathcal{A}$ 距离**(PAD)。

$\mathcal{A}$ 距离被定义为(其中 $\mathcal{A}$ 是 $X$ 的子集) $d_{\mathcal{A}}(\mathcal{D}\_S^X,\mathcal{D}\_T^X)=2sup_{A\in\mathcal{A}}|Pr_{\mathcal{D}\_S^X}(A)-Pr_{\mathcal{D}\_T^X}(A)|$

通过选择 $\mathcal{A}=\{A_{\eta}|\eta\in\mathcal{H}\}$ (其中 $A_{\eta}$ 是由特征函数 $η$ 表示的集合)，定义1的 $\mathcal{H}$ 散度和 $\mathcal{A}$ 距离是等价的。

#### 目标风险的泛化界

$\mathcal{H}$ 散度 $d_{\mathcal{H}}(\mathcal{D}_S^X,\mathcal{D}_T^X)$ 由其经验估计加上一个常数复杂项(取决于 $\mathcal{H}$ 的 $VC$ 维度、 $S$ 和 $T$ 的样本大小)作为上限。通过将这一结果与源域风险的类似界限相结合，得到以下**定理2**：

![\<img alt="" data-attachment-key="9KWV9VXI" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22N33RMEKB%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B86.705%2C449.122%2C523.606%2C620.28%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%227%22%7D%7D" width="728" height="285" src="attachments/9KWV9VXI.png" ztype="zimage">](attachments/9KWV9VXI.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 7</a></span>)</span>

说明只有当 $\beta$ 项较低时，即只有当存在能够在两种分布上实现低风险的分类器时， $R_{\mathcal{D}_T}(\eta)$ 才能较低。

要在固定的 $VC$ 维条件下从给定类中找到一个使 $R_{\mathcal{D}\_T}(\eta)$ 较小的分类器，学习算法应该（在该类中）最小化源域风险 $R_S(\eta)$ 和经验 $\mathcal{H}$ <span style="background-color: rgb(255, 255, 255)">散度</span> $\hat{d}\_{\mathcal{H}}(S,T)$ 之间的权衡。而控制 $\mathcal{H}$ <span style="background-color: rgb(255, 255, 255)">散度</span>的策略是找到源域和目标域尽可能无法区分的示例的表示。

在这种表示下，根据定理2，具有较低源域风险的假设将在目标数据上表现良好。

### 领域对抗神经网络(DANN)

本文将定理2所展示的思想明确地实现到神经网络分类器中。即为了学习一个可以从一个领域很好地推广到另一个领域的模型，需确保神经网络的内部表示不包含关于输入来源（源域或目标域）的辨别信息，同时保持源域（标记）示例的低风险。

#### 浅层神经网络示例

首先考虑具有单个隐藏层的标准神经网络架构。

假设输入空间由 $m$ 维实向量组成( $X=\mathbb{R}^m$ )，隐藏层 $G_f$ 学习一个将示例映射到新的 $D$ 维表示 $\mathbb{R}^D$ 的函数 $G_f:X\rightarrow\mathbb{R}^D$ 并且由一对矩阵向量 $(W,b)\in\mathbb{R}^{D\times m}\times\mathbb{R}^D$ 参数化。

![\<img alt="" data-attachment-key="UG5Y7Q9L" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22WSGNJSSF%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B83.89%2C605.641%2C381.163%2C657.439%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%228%22%7D%7D" width="495" height="86" src="attachments/UG5Y7Q9L.png" ztype="zimage">](attachments/UG5Y7Q9L.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 8</a></span>)</span>

预测层 $G_y$ 学习函数 $G_y:\mathbb{R}^D\rightarrow[0,1]^L$ ，其由一对矩阵向量 $(V,c)\in\mathbb{R}^{L\times D}\times\mathbb{R}^L$ 参数化( $L=|Y|$ )。

![\<img alt="" data-attachment-key="MKZT5AKD" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22X227RQHT%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B88.957%2C512.18%2C404.247%2C570.171%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%228%22%7D%7D" width="525" height="97" src="attachments/MKZT5AKD.png" ztype="zimage">](attachments/MKZT5AKD.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 8</a></span>)</span>

通过使用softmax函数，向量 $G_y(G_f(x))$ 的每个分量表示神经网络将 $x$ 分配给由该分量表示的 $Y$ 中类的条件概率。

损失是正确标签的负对数概率：

![\<img alt="" data-attachment-key="36TNI5VI" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22P45BXX4M%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B205.501%2C420.971%2C399.179%2C449.685%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%228%22%7D%7D" width="323" height="48" src="attachments/36TNI5VI.png" ztype="zimage">](attachments/36TNI5VI.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 8</a></span>)</span>

训练神经网络就得到源域上的优化问题：

![\<img alt="" data-attachment-key="RAGYKI2W" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%222HKIUGBV%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B191.426%2C357.351%2C414.944%2C397.325%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%228%22%7D%7D" width="373" height="67" src="attachments/RAGYKI2W.png" ztype="zimage">](attachments/RAGYKI2W.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 8</a></span>)</span>

其中 $\mathcal{L}_y^i(W,b,V,c)=\mathcal{L}_y(G_y(G_f(x_i;W,b);V,c),y_i)$ 为第 $i$ 个示例中预测损失的缩写， $R(W,b)$ 是可选的正则化项，由超参数 $\lambda$ 加权。

此时min意味着负对数概率中 $G_y(G_f(x))_{y_i}$ 尽可能大，即希望源域预测正确。

本文方法的核心是设计一个直接从定义1的 $\mathcal{H}$ <span style="background-color: rgb(255, 255, 255)">散度</span>导出的域正则化项，为此，将隐藏层 $G_f(\cdot)$ 的输出视为神经网络的内部表示。

将源样本表示为： $S(G_f)=\{G_f(x)|x\in S\}$ ；类似地给定来自目标域的未标记样本表示： $T(G_f)=\{G_f(x)|x\in T\}$ 。样本 $S(G_f)$ 和 $T(G_f)$ 之间对称假设类 $\mathcal{H}$ 的经验 $\mathcal{H}$ 散度为：

![\<img alt="" data-attachment-key="TJVZXHIH" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22YNH725ZN%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%228%22%2C%22position%22%3A%7B%22pageIndex%22%3A7%2C%22rects%22%3A%5B%5B94.024%2C113.564%2C498.833%2C152.412%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%228%22%7D%7D" width="675" height="65" src="attachments/TJVZXHIH.png" ztype="zimage">](attachments/TJVZXHIH.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%228%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 8</a></span>)</span>

考虑 $\mathcal{H}$ 作为表示空间中的超平面类。受到代理 $\mathcal{A}$ 距离的启发，通过学习逻辑回归函数 $G_d:\mathbb{R}^D\rightarrow[0,1]$ 的域分类层 $G_d$ (由一对向量-标量 $(u,z)\in\mathbb{R}^D\times\mathbb{R}$ 参数化)来估计上图方程的“min”部分，其对给定输入来自源域 $D^X_S$ 或目标域 $D^X_T$ 的概率进行建模：

![\<img alt="" data-attachment-key="2YX5F7XU" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22AQJ6R6RW%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B206.62700000000007%2C606.5420457546932%2C398.0529999999999%2C623.9955876130186%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%229%22%7D%7D" width="319" height="29" src="attachments/2YX5F7XU.png" ztype="zimage">](attachments/2YX5F7XU.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 9</a></span>)</span>

其损失为：

![\<img alt="" data-attachment-key="GMBP2UZ4" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22D4M9BMLL%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B135.687%2C547.5378122057734%2C470.12%2C577.3777386087171%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%229%22%7D%7D" width="557" height="50" src="attachments/GMBP2UZ4.png" ztype="zimage">](attachments/GMBP2UZ4.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 9</a></span>)</span>

其中 $d_i$ 表示第 $i$ 个示例的二进制变量(域标签)，其表示 $x_i$ 是来自源域分布(若 $d_i=0$ ，则 $x_i\sim D^X_S$ )还是目标域分布(若 $d_i=1$ ，则 $x_i\sim D^X_T$ )。

对于源域分布( $d_i=0$ )中的示例，相应的标签 $y_i\in Y$ 在训练时是已知的，而来自目标域的示例在训练时标签未知，为在测试时预测这些标签，给出域适应正则化项：

![\<img alt="" data-attachment-key="29L8EXAV" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22PHNDQB3M%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B131.183%2C386.6269999999997%2C456.4382687509883%2C425.4756209751607%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%229%22%7D%7D" width="542" height="65" src="attachments/29L8EXAV.png" ztype="zimage">](attachments/29L8EXAV.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 9</a></span>)</span>

其中 $\mathcal{L}\_d^i(W,b,u,z)=\mathcal{L}\_d(G_d(G_f(x_i;W,b);u,z),d_i)$ 。由于 $2(1−R(W,b))$ 是 $\hat{d}\_{\mathcal{H}}(S(G_f),T(G_f))$ 的替代，所以此正则化项寻求关于 $\hat{d}\_{\mathcal{H}}(S(G_f),T(G_f))$ 的 $\mathcal{H}$ <span style="background-color: rgb(255, 255, 255)">散度的近似。</span>

此时，将损失负对数写成对数形式，再提取负号，即可将 $R(W,b)$ 写成GAN的损失函数类似形式，max最大化意味着判别器希望准确区分样本的来源，但 $R(W,b)$ 在整体目标函数中又被min最小化，这就形成了对抗。

根据定理2，前述优化问题和正则化项实现了源域风险最小化 $R_S(\cdot)$ 和散度 $\hat{d}_{\mathcal{H}}(\cdot,\cdot)$ 之间的权衡。然后使用超参数 $\lambda$ 来调整学习过程中这两个量之间的权衡。

可以将完整优化目标重写：

![\<img alt="" data-attachment-key="84HFPGHI" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22KWAMTAZU%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B101.906%2C202.521%2C507.842%2C257.133%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%229%22%7D%7D" width="677" height="91" src="attachments/84HFPGHI.png" ztype="zimage">](attachments/84HFPGHI.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 9</a></span>)</span>

通过下式寻找传递鞍点的参数 $\hat{W},\hat{V},\hat{b},\hat{c},\hat{u},\hat{z}$ ：

![\<img alt="" data-attachment-key="8PXY5C3C" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22LYIQZCJF%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B192.552%2C119.75699999999992%2C412.692%2C171.4421274418553%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%229%22%7D%7D" width="367" height="86" src="attachments/8PXY5C3C.png" ztype="zimage">](attachments/8PXY5C3C.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 9</a></span>)</span>

本文用一个简单的随机梯度程序来解决这个问题，对于最小化参数，在完整优化目标的梯度相反方向上进行更新，对于最大化参数，在梯度的方向上进行。使用训练样本的子集计算平均值，对梯度进行随机估计。

![\<img alt="" data-attachment-key="34GUD4Z4" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%223FFVL7GU%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2210%22%2C%22position%22%3A%7B%22pageIndex%22%3A9%2C%22rects%22%3A%5B%5B86.705%2C353.409%2C523.606%2C703.606%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2210%22%7D%7D" width="728" height="584" src="attachments/34GUD4Z4.png" ztype="zimage">](attachments/34GUD4Z4.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2210%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 10</a></span>)</span>

换句话说，在训练期间，神经网络(由W,b,V,c参数化)和域回归器(由u,z参数化)以对抗的方式在目标上相互竞争——域对抗神经网络(DANN)。

DANN将有效地尝试学习隐藏层 $G_f$ ，该层将示例(源或目标)映射到表示中，允许输出层 $G_y$ 准确地对源域样本进行分类，但削弱了域回归器 $G_d$ 检测每个示例是否属于源域或目标域的能力。

#### 推广至任意构造

此时设 $G_f(\cdot;\theta_f)$ 为 $D$ 维神经网络特征提取器，参数为 $\theta_f$ 。假设 $G_y(\cdot;\theta_y)$ 是DANN的一部分，计算网络的标签预测输出层，参数为 $\theta_y$ 。而 $G_d(\cdot;\theta_d)$ 对应于网络的域预测输出计算，参数为 $\theta_d$ 。

为了维持定理2的理论保证，由域预测组件 $G_d$ 生成的假设类 $\mathcal{H}_d$ 应该包括由标签预测组件 $G_y$ 生成的假设类 $\mathcal{H}_y$ 。这样 $\mathcal{H}$ 散度可被域适应正则化项<span style="background-color: rgb(255, 255, 255)">界定住。</span>

预测损失与域损失：

![\<img alt="" data-attachment-key="LA428A7Z" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22MF6FYYIV%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B203.812%2C446.307%2C401.994%2C484.029%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2211%22%7D%7D" width="330" height="63" src="attachments/LA428A7Z.png" ztype="zimage">](attachments/LA428A7Z.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 11</a></span>)</span>

优化：

![\<img alt="" data-attachment-key="2IQ3PDD7" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%2288H3BYDW%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B120.486%2C378.182%2C467.30499999999995%2C415.6791202717127%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2211%22%7D%7D" width="578" height="62" src="attachments/2IQ3PDD7.png" ztype="zimage">](attachments/2IQ3PDD7.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 11</a></span>)</span>

通过找到鞍点 $\hat{\theta_f},\hat{\theta_y},\hat{\theta_d}$ ，从而：

![\<img alt="" data-attachment-key="4LNX2KQ6" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22YKDVLNG2%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B224.08099999999996%2C291.47700000000003%2C383.978%2C344.7389178798084%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2211%22%7D%7D" width="266" height="89" src="attachments/4LNX2KQ6.png" ztype="zimage">](attachments/4LNX2KQ6.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 11</a></span>)</span>

由上图方程定义的鞍点可以被视为以下梯度更新的稳定点( $\mu$ 是学习率)：

![\<img alt="" data-attachment-key="3NN4CL2M" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%229HJTIGD6%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B211.695%2C147.345%2C389.608%2C248.688%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2211%22%7D%7D" width="297" height="169" src="attachments/3NN4CL2M.png" ztype="zimage">](attachments/3NN4CL2M.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 11</a></span>)</span>

上图与前文SGD过程相似，唯一的区别是在第一个公式中，从类别预测器和域预测器中是相减而不是求和（很重要，否则SGD将尝试使不同域的特征不同，以最小化域分类损失）。

这样的减法可以通过引入特殊的梯度反转层(GRL)来实现。在正向传播过程中，其充当单位转换。然而，在反向传播期间，GRL从后续层获取梯度并将其乘以−1，然后将其传递到前一层。该层不需要参数更新。GRL被插入到特征提取器 $G_f$ 和域分类器 $G_d$ 之间。

![\<img alt="" data-attachment-key="JG2ZWGU7" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22BSCU83NG%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2212%22%2C%22position%22%3A%7B%22pageIndex%22%3A11%2C%22rects%22%3A%5B%5B117.50174621188974%2C544.8353265869366%2C489.09328255043613%2C703.0432382704691%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2212%22%7D%7D" width="619" height="264" src="attachments/JG2ZWGU7.png" ztype="zimage">](attachments/JG2ZWGU7.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2212%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 12</a></span>)</span>

数学上，可以将梯度反转层形式化地视为“伪函数” $R(x)$ ，由描述其正向和反向传播行为的两个(不相容的)方程定义：

![\<img alt="" data-attachment-key="Q2WA9VRZ" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%227CNXKVAS%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2213%22%2C%22position%22%3A%7B%22pageIndex%22%3A12%2C%22rects%22%3A%5B%5B271.937%2C553.281%2C329.928%2C598.885%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2213%22%7D%7D" width="97" height="76" src="attachments/Q2WA9VRZ.png" ztype="zimage">](attachments/Q2WA9VRZ.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2213%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 13</a></span>)</span>

然后可以定义 $(\theta_f,\theta_y,\theta_d)$ 的目标“伪函数”，该函数通过随机梯度下降进行优化：

![\<img alt="" data-attachment-key="TR36XAFS" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22F8EV2XC2%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2213%22%2C%22position%22%3A%7B%22pageIndex%22%3A12%2C%22rects%22%3A%5B%5B108.662%2C444.055%2C524.169%2C516.121%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2213%22%7D%7D" width="693" height="120" src="attachments/TR36XAFS.png" ztype="zimage">](attachments/TR36XAFS.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2213%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 13</a></span>)</span>

## 结论及改进方向

### 实验

#### 浅层神经网络实验

Toy Problem

![\<img alt="" data-attachment-key="TCSVQKCV" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22QW596V7B%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2214%22%2C%22position%22%3A%7B%22pageIndex%22%3A13%2C%22rects%22%3A%5B%5B84.45300000000002%2C410.8371665133395%2C526.984%2C708.11%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2214%22%7D%7D" width="738" height="496" src="attachments/TCSVQKCV.png" ztype="zimage">](attachments/TCSVQKCV.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2214%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 14</a></span>)</span>

情感分析\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2214%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 14</a></span>)</span>

![\<img alt="" data-attachment-key="RKLWTWL4" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22VI6MWILW%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2217%22%2C%22position%22%3A%7B%22pageIndex%22%3A16%2C%22rects%22%3A%5B%5B83.327%2C321.88%2C524.732%2C710.925%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2217%22%7D%7D" width="736" height="649" src="attachments/RKLWTWL4.png" ztype="zimage">](attachments/RKLWTWL4.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2217%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 17</a></span>)</span>

代理距离测试

![\<img alt="" data-attachment-key="VPL58ICT" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22QILJZEQC%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2219%22%2C%22position%22%3A%7B%22pageIndex%22%3A18%2C%22rects%22%3A%5B%5B81.638%2C522.315%2C525.295%2C700.228%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2219%22%7D%7D" width="739" height="296" src="attachments/VPL58ICT.png" ztype="zimage">](attachments/VPL58ICT.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2219%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 19</a></span>)</span>

#### 基于深度网络的图像分类实验

![\<img alt="" data-attachment-key="PZN7MTFC" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%227V7DRUW8%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2222%22%2C%22position%22%3A%7B%22pageIndex%22%3A21%2C%22rects%22%3A%5B%5B86.142%2C414.778%2C526.421%2C709.236%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2222%22%7D%7D" width="734" height="491" src="attachments/PZN7MTFC.png" ztype="zimage">](attachments/PZN7MTFC.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 22</a></span>)</span>

上图表示适应对提取的特征分布的影响。显示了t-SNE对CNN激活的可视化。(a)为未进行适应的情况，(b)为将本文适应程序纳入训练的情况。蓝色点对应于源域示例，而红色点对应于目标域。在所有情况下，本文方法中的适应使特征的两个分布更加接近。

![\<img alt="" data-attachment-key="JZJM8MZS" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22NKATQ6AX%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2224%22%2C%22position%22%3A%7B%22pageIndex%22%3A23%2C%22rects%22%3A%5B%5B122.56890352559721%2C620.2800000000001%2C483.46310775742785%2C702.48%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2224%22%7D%7D" width="601" height="137" src="attachments/JZJM8MZS.png" ztype="zimage">](attachments/JZJM8MZS.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 24</a></span>)</span>

![\<img alt="" data-attachment-key="5IDX4ZYS" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22CVWPJM6C%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2224%22%2C%22position%22%3A%7B%22pageIndex%22%3A23%2C%22rects%22%3A%5B%5B85.016%2C482.34%2C526.421%2C585.936%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2224%22%7D%7D" width="736" height="173" src="attachments/5IDX4ZYS.png" ztype="zimage">](attachments/5IDX4ZYS.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 24</a></span>)</span>

![\<img alt="" data-attachment-key="MWEAX85D" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22X2UWHW4H%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2224%22%2C%22position%22%3A%7B%22pageIndex%22%3A23%2C%22rects%22%3A%5B%5B124.82097344280052%2C169.75307500395323%2C477.26991548511876%2C317.8266720600709%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2224%22%7D%7D" width="587" height="247" src="attachments/MWEAX85D.png" ztype="zimage">](attachments/MWEAX85D.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 24</a></span>)</span>

#### 用深度图像描述进行重识别实验

给定两组来自不同相机(probe和gallery)的图像，使得probe集合中描绘的每个人在gallery集合中都有一个图像，对于probe集合中的每个人的图像，在gallery集合找到同一个人的图像。

不连续的相机视图、不同的照明条件、不同的姿势和低质量的数据使这个问题甚至对人类来说都很困难。

![\<img alt="" data-attachment-key="2K5HUR5J" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22V66XY4JY%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2227%22%2C%22position%22%3A%7B%22pageIndex%22%3A26%2C%22rects%22%3A%5B%5B86.705%2C561.163%2C523.043%2C712.052%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2227%22%7D%7D" width="727" height="251" src="attachments/2K5HUR5J.png" ztype="zimage">](attachments/2K5HUR5J.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 27</a></span>)</span>

![\<img alt="" data-attachment-key="K5HSEC5V" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%227ZV9L7BE%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2229%22%2C%22position%22%3A%7B%22pageIndex%22%3A28%2C%22rects%22%3A%5B%5B94.5%2C194.25%2C559.5%2C671.25%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2229%22%7D%7D" width="775" height="795" src="attachments/K5HSEC5V.png" ztype="zimage">](attachments/K5HSEC5V.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 29</a></span>)</span>

![\<img alt="" data-attachment-key="MMWXC54B" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22VE8P3ZG6%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2230%22%2C%22position%22%3A%7B%22pageIndex%22%3A29%2C%22rects%22%3A%5B%5B122.175%2C481.214%2C492.077%2C695.724%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2230%22%7D%7D" width="617" height="358" src="attachments/MMWXC54B.png" ztype="zimage">](attachments/MMWXC54B.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2230%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 30</a></span>)</span>

### 未来工作

作为额外实验，本文还评估了所提出的半监督域适应算法，即额外提供少量标记的目标数据。下图显示了整个训练过程中验证错误的变化。虽然该图清楚地表明，方法在半监督设置中是有益的，但对半监督设置的彻底验证仍有待于未来的工作。

![\<img alt="" data-attachment-key="R4HURZ6C" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FJ6JJQIM8%22%2C%22annotationKey%22%3A%22SFI3DTXU%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%2225%22%2C%22position%22%3A%7B%22pageIndex%22%3A24%2C%22rects%22%3A%5B%5B186.359%2C557.785%2C421.137%2C711.489%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2225%22%7D%7D" width="391" height="256" src="attachments/R4HURZ6C.png" ztype="zimage">](attachments/R4HURZ6C.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FA2TZBVKI%22%5D%2C%22locator%22%3A%2225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/A2TZBVKI">Ganin 等, 2017, p. 25</a></span>)</span>
