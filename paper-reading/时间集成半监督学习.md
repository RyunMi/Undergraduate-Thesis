# 时间集成半监督学习

## 引用方式

### GB/T 7714

<span style="background-color: rgb(255, 255, 255)">Laine S, Aila T. Temporal ensembling for semi-supervised learning[J]. arXiv preprint arXiv:1610.02242, 2016.</span>

### BibTex

    @article{laine2016temporal,
      title={Temporal ensembling for semi-supervised learning},
      author={Laine, Samuli and Aila, Timo},
      journal={arXiv preprint arXiv:1610.02242},
      year={2016}
    }

## 开源代码

[ferretj/temporal-ensembling: PyTorch implementation of Temporal Ensembling for Semi-Supervised Learning (github.com)](https://github.com/ferretj/temporal-ensembling)

## 主要思想

本文提出了一种简单有效的方法，用于在半监督环境中训练深度神经网络，其中只有一小部分训练数据被标记。

本文引入了自集成，在不同epoch的训练中，最重要的是，在不同的正则化和输入增加条件下，使用网络的输出来形成未知标签的一致预测。与最近训练时期的网络输出相比，该集合预测可以被期望为未知标签的更好的预测器，并且因此可以被用作训练的目标。

使用此方法为两个标准的半监督学习基准设置了新的记录，在具有500个标签的SVHN中，将（非增强）分类错误率从18.44%降低到7.05%，在具有4000个标签的CIFAR-10中，将从18.63%降低到16.55%，并通过启用标准增强进一步降低到5.12%和12.16%。

此外，通过在训练期间使用来自微小图像数据集的随机图像作为未标记的额外输入，在CIFAR-100分类精度方面获得了明显的提高。最后，本文展示了对不正确标签的良好容忍度。

## 主要内容

### 引论

众所周知，与单个神经网络相比，多个神经网络的集合通常能够产生更好的预测结果。当通过dropout、dropconnect或随机深度正则化方法以及Swapout网络训练单个网络时，也会间接利用这种效应，其中的训练始终集中在网络的特定子集上，因此完整网络可以被视为训练好的子网络的隐式集合。

本文通过在训练期间形成集合预测来扩展这一思想，在不同的训练epoch以及在不同的正则化和输入增强条件下使用单个网络的输出。训练仍然在单个网络上进行，但由于dropout正则化，在不同时期进行的预测对应于大量单独子网络的集合预测。

对于SSL，如果将集合预测与正在训练的网络的当前输出进行比较，则集合预测可能更接近未标记输入的正确、未知标签。因此，以这种方式推断的标签可以用作未标记输入的训练目标。

本文方法在很大程度上依赖于dropout正则化和多功能输入增强。事实上，如果两者都没有，很难信任未标记的训练数据所推断的任何标签。

### 训练中的自集合

在传统图像分类网络的背景下，设训练数据由总共 $N$ 个输入组成，其中 $M$ 个被标记。可用于所有训练数据的输入**刺激**用 $x_i$ 表示，其中 $i\in\{1\dots N\}$ 。设集合 $L$ 包含标记输入的索引， $|L|=M$ 。对于每个 $i\in L$ ，有一个已知的正确标签 $y_i\in\{1\dots C\}$ ，其中 $C$ 是不同类的数量。

#### π-模型

![\<img alt="" data-attachment-key="TKPCKGHJ" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FC2D94MJB%22%2C%22annotationKey%22%3A%22TQTE9R6Z%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B113.73%2C641.674%2C490.388%2C710.362%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%222%22%7D%7D" width="628" height="115" src="attachments/TKPCKGHJ.png" ztype="zimage">](attachments/TKPCKGHJ.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/PJ283S63">Laine 和 Aila, 2017, p. 2</a></span>)</span>

在训练期间，对每个训练输入 $x_i$ 的网络进行两次评估，得出预测向量 $z_i$ 和 $\tilde{z}_i$ 。

损失函数由两部分组成。第一个部分是标准交叉熵损失，仅针对标记输入进行评估。第二个部分针对所有输入进行评估，通过计算预测向量 $z_i$ 和 $\tilde{z}_i$ 之间的均方差，对同一训练输入 $x_i$ 的不同预测进行惩罚。为了将监督和非监督损失项相结合，通过时间相关加权函数 $w(t)$ 对后者进行缩放。

通过比较整个输出向量 $z_i$ 和 $\tilde{z}_i$ ，本文有效地要求两个评估之间的“dark knowledge”相似，这比只要求最终分类保持相同(传统训练中发生的情况)要求更强烈。

需要注意的是，由于dropout正则化，训练期间的网络输出是一个随机变量。因此在相同网络权重 $\theta$ 下对相同输入 $x_i$ 进行的两次评估产生了不同的结果。另外，高斯噪声和增强技术(例如随机平移)被评估了两次，导致了额外的变化。这些效应的结合说明了预测向量 $z_i$ 和 $\tilde{z}_i$ 之间的差异。鉴于原始输入 $x_i$ 相同，该差异可视为分类错误，因此将其最小化是一个合理的目标。

![\<img alt="" data-attachment-key="JZGZJYHM" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FC2D94MJB%22%2C%22annotationKey%22%3A%22ADSAJMGG%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B104.818%2C302.851%2C504.928%2C507.978%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%222%22%7D%7D" width="667" height="342" src="attachments/JZGZJYHM.png" ztype="zimage">](attachments/JZGZJYHM.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/PJ283S63">Laine 和 Aila, 2017, p. 2</a></span>)</span>

在实践中，无监督损失加权函数 $w(t)$ 在前80个训练epoch期间沿着高斯曲线从零开始逐渐增加，因此开始时，总损失和学习梯度由受监督的损失组成，即仅使用标记的数据。非监督损失部分的逐步升级非常重要，否则网络很容易陷入退化解决方案，无法获得数据的有意义分类。

#### 时序集成

由于以 $\Pi$ 模型获得的训练目标基于网络的单次评估，因此预计会产生噪音。时序集成通过将多个以前的网络评估的预测聚合成集合预测来缓解此问题。其使得在训练期间仅评估网络一次，从而获得 $\Pi$ 模型的近似2倍加速。

![\<img alt="" data-attachment-key="IWQ6L924" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FC2D94MJB%22%2C%22annotationKey%22%3A%22RWTB445H%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B113.834%2C563.768%2C490.84%2C640.972%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%222%22%7D%7D" width="628" height="129" src="attachments/IWQ6L924.png" ztype="zimage">](attachments/IWQ6L924.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/PJ283S63">Laine 和 Aila, 2017, p. 2</a></span>)</span>

与 $\Pi$ 模型的主要区别在于，网络和增强仅在每个输入的每个eopch评估一次，并且用于无监督损失部分的目标向量 $\tilde{z}$ 基于先前的网络评估，而不是对网络进行第二次评估。

在每个训练epoch后，通过更新 $Z_i\leftarrow \alpha Z_i+(1−\alpha)z_i$ ，将网络输出 $z_i$ 累积到集合输出 $Z_i$ 中，其中 $\alpha$ 是动量项，控制集合延伸到训练历史的程度。

由于dropout正则化和随机增强， $Z$ 因此包含来自先前训练epoch的网络集合 $f$ 的输出加权平均，其中近的epoch比远的epoch具有更大的权重。

为了生成训练目标 $\tilde{z}$ ，需要通过除以因子 $(1−\alpha^t)$ 来校正 $Z$ 中的启动偏差。

在第一个训练epoch，由于没有来自先前epoch的数据可用， $Z$ 和 $\tilde{z}$ 均为零。因此指定无监督权重回升函数 $w(t)$ 在第一个训练eopch也为零。

![\<img alt="" data-attachment-key="KZ9LGNLS" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FC2D94MJB%22%2C%22annotationKey%22%3A%22WCH4IFGE%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%224%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B104.818%2C451.061%2C504.928%2C711.978%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%224%22%7D%7D" width="667" height="435" src="attachments/KZ9LGNLS.png" ztype="zimage">](attachments/KZ9LGNLS.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%224%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/PJ283S63">Laine 和 Aila, 2017, p. 4</a></span>)</span>

与 $\Pi$ 模型相比，时序集成的优点有两个。首先，训练更快，因为每个eopch网络只进行一次输入评估。其次，预计训练目标 $\tilde{z}$ 要比 $\Pi$ 模型的目标更加清晰明了。与 $\Pi$ 模型相比的缺点是需要在epoch间存储辅助数据，以及新的超参数 $\alpha$ 。

时序集成的一个有趣的附加可能性是从网络预测 $z_i$ 中收集除平均值之外的其他统计信息。基于这些信息，可在无监督损失项中更加重视更确定的预测而非不确定的预测。

## 结论及改进方向

### 结果

网络结构如下图：

![\<img alt="" data-attachment-key="2V5B3H67" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FC2D94MJB%22%2C%22annotationKey%22%3A%22CB6GBPCI%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%229%22%2C%22position%22%3A%7B%22pageIndex%22%3A8%2C%22rects%22%3A%5B%5B173.569%2C467.403%2C436.74%2C685.492%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%229%22%7D%7D" width="439" height="364" src="attachments/2V5B3H67.png" ztype="zimage">](attachments/2V5B3H67.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%229%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/PJ283S63">Laine 和 Aila, 2017, p. 9</a></span>)</span>

在纯监督训练中，扩充 CIFAR-10 数据集的事实标准方法包括水平翻转和随机平移，而 SVHN 仅限于随机平移。通过使用这些相同的数据扩充，可以将结果与最佳完全监督结果进行比较。毕竟，完全监督的结果应该表明可获得精度的上限。

#### CIFAR-10

![\<img alt="" data-attachment-key="TWAAP59J" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FC2D94MJB%22%2C%22annotationKey%22%3A%227GSF5TUE%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B108.199%2C564.895%2C503.238%2C681.547%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%225%22%7D%7D" width="658" height="194" src="attachments/TWAAP59J.png" ztype="zimage">](attachments/TWAAP59J.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/PJ283S63">Laine 和 Aila, 2017, p. 5</a></span>)</span>

#### SVHN

![\<img alt="" data-attachment-key="VVF645D5" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FC2D94MJB%22%2C%22annotationKey%22%3A%22543Z3MAU%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%225%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B110.453%2C386.254%2C502.11%2C522.63%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%225%22%7D%7D" width="653" height="227" src="attachments/VVF645D5.png" ztype="zimage">](attachments/VVF645D5.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%225%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/PJ283S63">Laine 和 Aila, 2017, p. 5</a></span>)</span>

#### CIFAR-100和Tiny Images

![\<img alt="" data-attachment-key="3PPWW5RR" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FC2D94MJB%22%2C%22annotationKey%22%3A%224ZMFHVGE%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B109.326%2C598.707%2C502.11%2C681.547%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%226%22%7D%7D" width="655" height="138" src="attachments/3PPWW5RR.png" ztype="zimage">](attachments/3PPWW5RR.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/PJ283S63">Laine 和 Aila, 2017, p. 6</a></span>)</span>

接着使用Tiny Images数据集中未标记的额外数据进行了两项额外测试：一项是随机选择的500k张额外图像，大多数与CIFAR100类别中的任何类别都不对应，另一项是来自与CIFAR-100数据集中发现的类别相对应的237k张图像的限制集。

![\<img alt="" data-attachment-key="Q8H6H388" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FC2D94MJB%22%2C%22annotationKey%22%3A%229WTF66IW%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%226%22%2C%22position%22%3A%7B%22pageIndex%22%3A5%2C%22rects%22%3A%5B%5B110.453%2C498.961%2C502.11%2C559.823%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%226%22%7D%7D" width="653" height="101" src="attachments/Q8H6H388.png" ztype="zimage">](attachments/Q8H6H388.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%226%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/PJ283S63">Laine 和 Aila, 2017, p. 6</a></span>)</span>

为了通过添加额外的未标记的输入数据来训练更好的分类器，只需要将额外的数据大致放在实际输入数据所在的同一空间中，即自然图像。

#### 对错误标签的容忍

在进一步的测试中，本文研究了方法是否通过在开始训练之前向一定百分比的训练集分配随机标签来添加对不正确标签的容忍度的假设。下图显示了标准监督训练和时间合成的分类误差图。

![\<img alt="" data-attachment-key="LWFZYDXS" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FC2D94MJB%22%2C%22annotationKey%22%3A%22DPPDXA46%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B109.326%2C583.492%2C504.928%2C710.851%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%227%22%7D%7D" width="659" height="212" src="attachments/LWFZYDXS.png" ztype="zimage">](attachments/LWFZYDXS.png)\
<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F8273795%2Fitems%2FPJ283S63%22%5D%2C%22locator%22%3A%227%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/PJ283S63">Laine 和 Aila, 2017, p. 7</a></span>)</span>

显然，方法对错误标签提供了相当大的抵抗力，这是因为无监督损失项鼓励网络实现的映射函数在所有输入数据点附近具有平坦的特性，而监督损失项则强制使映射函数在标记输入数据点附近具有特定的值。

这意味着即使是错误标记的输入也会在塑造映射函数中起作用——无监督损失项使映射函数平滑化，因此也使决策边界平滑化，有效地将输入融合成连贯的聚类，而每个类别中的过多正确标签足以通过受监督的损失项将聚类锁定到正确的输出向量。

与传统的正则化方法不同的是，本文仅对可能输入的流形进行平滑处理，而不是整个输入域。

### 未来工作

生成对抗性网络最近被用于半监督学习，并取得了有希望的结果。将生成部分纳入本文的解决方案可能是未来工作的一个有趣途径。

还设想：本文的方法可以应用于回归型学习任务。
